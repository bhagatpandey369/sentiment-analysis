{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP24pjNBJz3QkN4O28noloF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhagatpandey369/sentiment-analysis/blob/main/sentimental_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Workflow**\n",
        "1. Import Libararies\n",
        "2. Preparing Data\n",
        "3. Build a model\n",
        "4. loss fuction and optimizer\n",
        "5. train and evaluation\n",
        "6. train the model\n",
        "7. visulization our model\n",
        "8. testing model"
      ],
      "metadata": {
        "id": "gmpKWe8G52B5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtaXfbNw5HZX"
      },
      "outputs": [],
      "source": [
        "!pip install datasets torchtext torchdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praparing data**\n",
        "1. Load data\n",
        "2. Tokenization data\n",
        "3. creating data splits\n",
        "4. creating a vocabulary\n",
        "5. numericaling data\n",
        "6. conveting into tensor\n",
        "7. creating the data loader\n"
      ],
      "metadata": {
        "id": "oY4j07Bm6s-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "e1u6W6Wt6koR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = datasets.load_dataset('imdb',split=['train','test'])"
      ],
      "metadata": {
        "id": "Wur7b-Br6ky4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "HQuh_95F6k3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.features"
      ],
      "metadata": {
        "id": "i2Q_HnnL9BOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[24999]"
      ],
      "metadata": {
        "id": "jazqyCHb9BQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "TQDtD1659j6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n"
      ],
      "metadata": {
        "id": "KWpGpWwR9BSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer('Hi my name is Bhagat Pandey and my email address is pandeybhagat369@gmail.com')"
      ],
      "metadata": {
        "id": "GRM614Uy9BX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_example(example,tokenizer,max_length):\n",
        "  tokens = tokenizer(example['text'])[:max_length]\n",
        "  return {'tokens': tokens}"
      ],
      "metadata": {
        "id": "DKfUcxDQ9Bbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256\n",
        "train_data = train_data.map(\n",
        "    tokenize_example,\n",
        "    fn_kwargs={'tokenizer':tokenizer,'max_length':max_length}\n",
        ")\n",
        "test_data = test_data.map(\n",
        "    tokenize_example,\n",
        "    fn_kwargs={'tokenizer':tokenizer,'max_length':max_length}\n",
        ")"
      ],
      "metadata": {
        "id": "OypzwEOSC77X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "yU-6-wFZEw6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.features"
      ],
      "metadata": {
        "id": "iRZT48EKFCac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[24999]['tokens'][:25]"
      ],
      "metadata": {
        "id": "1n30yGEZFCd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.25\n",
        "train_valid_data  = train_data.train_test_split(test_size=test_size)\n",
        "train_data = train_valid_data['train']\n",
        "valid_data = train_valid_data['test']"
      ],
      "metadata": {
        "id": "gQBtY8YtFCiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_valid_data['train']"
      ],
      "metadata": {
        "id": "ZHUR66O7ImEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "metadata": {
        "id": "477heQVWImHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Vocabulary**"
      ],
      "metadata": {
        "id": "nccnaERIJJ5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_freq = 5\n",
        "special_tokens = ['<unk>','<pad>']\n",
        "vocab = build_vocab_from_iterator(\n",
        "    train_data['tokens'],\n",
        "    min_freq = min_freq,\n",
        "    specials = special_tokens\n",
        ")"
      ],
      "metadata": {
        "id": "vm1m1t_TJI4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "id": "JupTuYQbJI7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.get_itos()[:10]"
      ],
      "metadata": {
        "id": "Z5nmpVVVJI_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab['and']"
      ],
      "metadata": {
        "id": "qYzygQYtNk2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unk_index = vocab['<unk>']\n",
        "pad_index = vocab['<pad>']"
      ],
      "metadata": {
        "id": "294-ivOqNnhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'cat' in vocab"
      ],
      "metadata": {
        "id": "-G3K2Z94Oghr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'bhagat' in vocab"
      ],
      "metadata": {
        "id": "QWZD7foNOglT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.set_default_index(unk_index)"
      ],
      "metadata": {
        "id": "V_z-w0BHxorj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab['some token']"
      ],
      "metadata": {
        "id": "r0YXSWmzOpQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.lookup_indices(['and','bhagat','some token','cat','dog','kathmandu'])"
      ],
      "metadata": {
        "id": "u9CAwA7mOpVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Numericalization**"
      ],
      "metadata": {
        "id": "HOCkqZTqQLzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def numericalize_example(example, vocab):\n",
        "  ids = vocab.lookup_indices(example['tokens'])\n",
        "  return {'ids':ids}"
      ],
      "metadata": {
        "id": "VO_6LjmtQSpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.map(numericalize_example,fn_kwargs={'vocab':vocab})\n",
        "valid_data = valid_data.map(numericalize_example,fn_kwargs={'vocab':vocab})\n",
        "test_data = test_data.map(numericalize_example,fn_kwargs={'vocab':vocab})"
      ],
      "metadata": {
        "id": "bHViUarrQSs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "mVFthJMaSGuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]['tokens'][:5]"
      ],
      "metadata": {
        "id": "YzZ4gGm4SGyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]['ids'][:10]"
      ],
      "metadata": {
        "id": "iULOwT7OSG1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Converting into tensors**"
      ],
      "metadata": {
        "id": "3uHZwmtiSqO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "u4QooYx4Supd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.with_format(type='torch',columns=['ids','label'])\n",
        "valid_data = valid_data.with_format(type='torch',columns=['ids','label'])\n",
        "test_data = test_data.with_format(type='torch',columns=['ids','label'])"
      ],
      "metadata": {
        "id": "Il3lJeBwSuwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[100]"
      ],
      "metadata": {
        "id": "XXZLt95LTQhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[100]['label']"
      ],
      "metadata": {
        "id": "aWfWpxlwTomi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[100]['ids'][:10]"
      ],
      "metadata": {
        "id": "ToFPeC9EUM4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0].keys()"
      ],
      "metadata": {
        "id": "0_bevsHgUWJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.lookup_tokens(train_data[0]['ids'].tolist())"
      ],
      "metadata": {
        "id": "8rsNBxbSUWN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Data Loaders**"
      ],
      "metadata": {
        "id": "_0nAZafryLBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_collate_fn(pad_index):\n",
        "  def collate_fn(batch):\n",
        "    batch_ids = [i['ids'] for i in batch]\n",
        "    batch_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "        batch_ids,\n",
        "        padding_value = pad_index,\n",
        "        batch_first=True\n",
        "    )\n",
        "    batch_label = [i['label'] for i in batch]\n",
        "    batch_label = torch.stack(batch_label)\n",
        "    batch = {'ids':batch_ids,'label':batch_label}\n",
        "    return batch\n",
        "\n",
        "  return collate_fn\n"
      ],
      "metadata": {
        "id": "id-7kTT7yHLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset,batch_size, pad_index, shuffle=False):\n",
        "  collate_fn = get_collate_fn(pad_index)\n",
        "  data_loader = torch.utils.data.DataLoader(\n",
        "      dataset=dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      collate_fn=collate_fn\n",
        "  )\n",
        "  return data_loader"
      ],
      "metadata": {
        "id": "LLvzElVzUWYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_data_loader = get_data_loader(train_data,batch_size,pad_index,shuffle=True)\n",
        "valid_data_loader = get_data_loader(valid_data,batch_size,pad_index,shuffle=False)\n",
        "test_data_loader = get_data_loader(test_data,batch_size,pad_index,shuffle=False)"
      ],
      "metadata": {
        "id": "UMPaMsswUWco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_loader), len(valid_data_loader), len(test_data_loader)"
      ],
      "metadata": {
        "id": "PnXYZVg16zyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build the Model**"
      ],
      "metadata": {
        "id": "0GHjAQW67Ncv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NBow(nn.Module):\n",
        "  def __init__(self,vocab_size,embedding_dim,output_dim,pad_indes):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_dim,padding_idx=pad_index)\n",
        "    self.fc = nn.Linear(embedding_dim,output_dim)\n",
        "\n",
        "  def forward(self,ids):\n",
        "    embedded = self.embedding(ids)\n",
        "    pooled = embedded.mean(dim=1)\n",
        "    prediction = self.fc(pooled)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "VvqtE5Zt7Syt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 300\n",
        "output_dim = len(train_data.unique('label'))\n",
        "model = NBow(vocab_size,embedding_dim,output_dim,pad_index)"
      ],
      "metadata": {
        "id": "60P4edU37S5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "id": "LyLiZKyC7S_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data.unique('label'))"
      ],
      "metadata": {
        "id": "-htpvcOK9aeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
      ],
      "metadata": {
        "id": "F9EUJJ-N9aiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors=torchtext.vocab.GloVe()\n"
      ],
      "metadata": {
        "id": "8H9ZZtPV-bQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors.get_vecs_by_tokens(['and']).shape"
      ],
      "metadata": {
        "id": "HWbg3EmaAUf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors.get_vecs_by_tokens(['apple'])[:,:10]"
      ],
      "metadata": {
        "id": "RRX8_yl5AUwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())"
      ],
      "metadata": {
        "id": "abax1JLVC4YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_embedding.shape"
      ],
      "metadata": {
        "id": "CWETw6ouC4ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding"
      ],
      "metadata": {
        "id": "6PrkvxK1C4hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight"
      ],
      "metadata": {
        "id": "BQpvI20BC4kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_embedding"
      ],
      "metadata": {
        "id": "TiX6PVVnDyCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data = pretrain_embedding"
      ],
      "metadata": {
        "id": "pGhPD8oJDyGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight"
      ],
      "metadata": {
        "id": "F9VUmvo5EIVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss and Optimizer**"
      ],
      "metadata": {
        "id": "hYgEWrbQESHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "wsLCx3ImEOh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "7WLPjL0kEOls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "dj2XTD4dEOpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "ltZ36zBnEOs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RsNNrAd3HU1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train and Evaluation Model**"
      ],
      "metadata": {
        "id": "vgybUJkqFEjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader,model,criterion,optimizer,device):\n",
        "  model.train()\n",
        "  epoch_loss = []\n",
        "  epoch_acc = []\n",
        "  for batch in tqdm.tqdm(data_loader,desc='training...'):\n",
        "    ids = batch['ids'].to(device)\n",
        "    label = batch['label'].to(device)\n",
        "    prediction = model(ids)\n",
        "    loss = criterion(prediction, label)\n",
        "    accuracy = get_accuracy(prediction, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss.append(loss.item())\n",
        "    epoch_acc.append(accuracy.item())\n",
        "    return np.mean(epoch_loss), np.mean(epoch_acc)\n"
      ],
      "metadata": {
        "id": "ytJ2F3cmEO5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader,model,criterion,device):\n",
        "  model.eval()\n",
        "  epoch_loss = []\n",
        "  epoch_acc = []\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm.tqdm(data_loader,desc='evaluating...'):\n",
        "      ids = batch['ids'].to(device)\n",
        "      label = batch['label'].to(device)\n",
        "      prediction = model(ids)\n",
        "      loss = criterion(prediction, label)\n",
        "      accuracy = get_accuracy(prediction, label)\n",
        "      epoch_loss.append(loss.item())\n",
        "      epoch_acc.append(accuracy.item())\n",
        "  return np.mean(epoch_loss), np.mean(epoch_acc)"
      ],
      "metadata": {
        "id": "0O-YknKpHeO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(prediction,label):\n",
        "  batch_size,_=prediction.shape\n",
        "  predicted_classes=prediction.argmax(dim=-1)\n",
        "  correct_prediction=predicted_classes.eq(label).sum()\n",
        "  accuracy=correct_prediction / batch_size\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "h2Ksx6__Hu3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Loop**"
      ],
      "metadata": {
        "id": "XE_m4tt8H-bB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 15\n",
        "best_valid_loss = float('inf')\n",
        "metrics = collections.defaultdict(list)\n",
        "for epoch in range(n_epoch):\n",
        "  train_loss, train_acc = train(train_data_loader,model,criterion,optimizer,device)\n",
        "  valid_loss, valid_acc = evaluate(valid_data_loader,model,criterion,device)\n",
        "  metrics['train_loss'].append(train_loss)\n",
        "  metrics['train_acc'].append(train_acc)\n",
        "  metrics['valid_loss'].append(valid_loss)\n",
        "  metrics['valid_acc'].append(valid_acc)\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(),'nbow.pt')\n",
        "  print(f'Epoch: {epoch+1:02}')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n"
      ],
      "metadata": {
        "id": "Y-NI71_nHu7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visulization our Model**"
      ],
      "metadata": {
        "id": "DBW8suKRJTxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10,5))\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "ax.plot(metrics['train_loss'],label='train loss')\n",
        "ax.plot(metrics['valid_loss'],label='valid loss')\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('loss')\n",
        "ax.set_xticks(range(n_epoch))\n",
        "ax.legend()\n",
        "ax.grid()\n"
      ],
      "metadata": {
        "id": "ZwUwaQ0wHu_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig=plt.figure(figsize=(10,6))\n",
        "ax=fig.add_subplot(1,1,1)\n",
        "ax.plot(metrics['train_acc'],label='train acc')\n",
        "ax.plot(metrics['valid_acc'],label='valid acc')\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('accuracy')\n",
        "ax.set_xticks(range(n_epoch))\n",
        "ax.legend()\n",
        "ax.grid()"
      ],
      "metadata": {
        "id": "0FGAK84rKCSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('nbow.pt'))\n",
        "test_loss, test_acc = evaluate(test_data_loader,model,criterion,device)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "e7P1a7Q8LMEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text,model,tokenizer,vocab,device):\n",
        "  tokens = tokenizer(text)\n",
        "  ids = vocab.lookup_indices(tokens)\n",
        "  tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
        "  prediction = model(tensor).squeeze(dim=0)\n",
        "  probability = torch.softmax(prediction,dim=-1)\n",
        "  predicted_class = prediction.argmax(dim=-1).item()\n",
        "  predicted_probability = probability[predicted_class].item()\n",
        "  return predicted_class, predicted_probability"
      ],
      "metadata": {
        "id": "WdW0pC-MLL-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text=\"this film is terrible!\"\n",
        "predict_sentiment(text,model,tokenizer,vocab,device)"
      ],
      "metadata": {
        "id": "RZ3dgr6OLL64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text=\"this film is great!\"\n",
        "predict_sentiment(text,model,tokenizer,vocab,device)"
      ],
      "metadata": {
        "id": "TDByK_WzMom8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"This film is not great, it's terrible!\"\n",
        "\n",
        "predict_sentiment(text, model, tokenizer, vocab, device)"
      ],
      "metadata": {
        "id": "qZBiKGXJMop0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"This film is happy\"\n",
        "\n",
        "predict_sentiment(text, model, tokenizer, vocab, device)"
      ],
      "metadata": {
        "id": "CwWaJ5zrMosu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kNVr-rN3MovY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XuNnEm8sMox8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGg9gBHRMo0f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}